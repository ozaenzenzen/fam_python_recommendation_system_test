# -*- coding: utf-8 -*-
"""test_fam_recommendation_system_dcd (version 2 - cosmetics).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rSUW1rgO0DD62Yb7yhf3xgyB0kGfXP5b

#Import Library

Proses untuk menginisialisasi library yang akan dibutuhkan untuk proses mengolah data untuk Recommendation System
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""#Data Loading
Tahap untuk memuat informasi dataset ke dalam variabel dalam python
"""

url = "/content/drive/MyDrive/File Ozan/Repo Machine Learning/cosmetics.csv"

dataset_init = pd.read_csv(url)
dataset_init

"""Melihat informasi mengenai dataset antara lain
- Jumlah dan nama kolom
- Jumlah baris dari setiap kolom
- Tipe nullable atau tidak dari tiap kolom
- Tipe data dari tiap kolom
"""

dataset_init.info()

"""`dataset_init.describe()` Ditujukan untuk mendeskripsikan beberapa parameter untuk seluruh kolom dari dataset. Parameter tersebut antara lain
- Count atau jumlah baris dari setiap kolom
- Mean atau rata-rata dari setiap kolom
- Standar deviasi dari setiap kolom
- Nilai minimum / terkecil dari setiap kolom
- Nilai kuartil pertama atau 25% dari setiap kolom
- Nilai kuartil kedua atau 50% atau median dari setiap kolom
- Nilai kuartil ketiga atau 75% dari setiap kolom
- Nilai maximum / terbesar dari setiap kolom
"""

dataset_init.describe()

"""`dataset_init.columns` Ditujukan untuk mejabarkan kolom apa saja yang tersedia pada dataset yang digunakan"""

dataset_init.columns

"""`dataset_init.shape` Ditujukan untuk mejabarkan jumlah baris dan kolom pada dataset"""

dataset_init.shape

"""#Data Preparation
Tahap untuk mengolah data agar data siap digunakan untuk proses membuat sistem rekomendasi. Tahapan yang dilakukan antara lain
- `Check Missing Value` : Melakukan pengecekan missing value dalam data (bisa NULL atau 0) menyesuaikan analisis masalah
- `Univariate Analysis` : Pada tahap ini merupakan proses untuk mengeksplorasi dan menjelaskan setiap variabel dalam kumpulan data secara terpisah untuk 1 jenis variabel / kolom
- `Multivariate Analysis` : Pada tahap ini merupakan proses untuk mengeksplorasi dan menjelaskan setiap variabel dalam kumpulan data secara terpisah untuk 2 atau lebih jenis variabel / kolom

###Check Missing Value
"""

dataset = dataset_init
# dataset.isnull().sum()*100/dataset.shape[0]
dataset.isnull().sum()

"""###Univariate Analysis"""

numerical_features = ['Price', 'Rank', 'Combination','Dry', 'Normal', 'Oily', 'Sensitive']
categorical_features = ['Label', 'Brand']

df = dataset_init

"""#####Categorical Features"""

count = dataset['Label'].value_counts()
percent = 100*dataset['Label'].value_counts(normalize=True)
dfprint = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(dfprint)

plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='Label')
plt.title('Count of Label in Each Category')
plt.show()

plt.figure(figsize=(8, 6))
df['Label'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('Distribution of Label')
plt.ylabel('')
plt.show()

count = dataset['Brand'].value_counts()
percent = 100*dataset['Brand'].value_counts(normalize=True)
dfprint = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(dfprint)

plt.figure(figsize=(20, 6))
sns.countplot(data=df, x='Brand')
plt.title('Count of Brand in Each Category')
plt.xticks(rotation=90)
plt.show()

count_for_plot_highest = dataset['Brand'].value_counts().head(10)
count_for_plot_highest.plot(kind='bar', title='Brand' + ' ' + '(10 Highest)', rot=45, figsize=(12,5), fontsize=8)

count_for_plot_lowest = dataset['Brand'].value_counts().tail(10)
count_for_plot_lowest.plot(kind='bar', title='Brand' + ' ' + '(10 Lowest)', rot=45, figsize=(12,5), fontsize=8)

plt.figure(figsize=(8, 6))
df['Brand'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('Distribution of Brand')
plt.ylabel('')
plt.show()

"""#####Numerical Features"""

df.hist(bins=50, figsize=(20,15))
plt.show()

sns.set_style('whitegrid')
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Plot distribution of prices
sns.histplot(data=df, x='Price', bins=10, ax=axes[0])
axes[0].set_title('Distribution of Prices')

# Plot distribution of ratings
sns.histplot(data=df, x='Rank', bins=10, ax=axes[1])
axes[1].set_title('Distribution of Ranks')
plt.tight_layout()
plt.show()

"""###Multivariate Analysis"""

dataset = dataset_init

"""#####Categorical Features

Visualisasi untuk rata-rata kolom `Price` terhadap kolom kategorik `'Brand'` dan `'Label'`
"""

cat_features = dataset.select_dtypes(include='object').columns.difference(['Name','Ingredients']).to_list()

for col in cat_features:
  sns.catplot(x=col, y="Price", kind="bar", dodge=False, height = 4, aspect = 3,  data=dataset, palette="Set3")
  plt.title("Rata-rata 'Price' Relatif terhadap - {}".format(col))
  plt.xticks(rotation=90)

cat_features

"""Visualisasi untuk rata-rata kolom `Rank` terhadap kolom kategorik `'Brand'` dan `'Label'`"""

cat_features = dataset.select_dtypes(include='object').columns.difference(['Name','Ingredients']).to_list()

for col in cat_features:
  sns.catplot(x=col, y="Rank", kind="bar", dodge=False, height = 4, aspect = 3,  data=dataset, palette="Set3")
  plt.title("Rata-rata 'Rank' Relatif terhadap - {}".format(col))
  plt.xticks(rotation=90)

cat_features

"""#####Numerical Features"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = dataset.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=22)

"""#Content Based Filtering
Sistem *Content Based Filtering* adalah sistem yang merekomendasikan konten yang mirip dengan konten yang disukai pengguna sebelumnya. Jika suatu konten memiliki karakteristik yang sama atau hampir sama dengan konten lainnya, maka kedua konten tersebut dapat dikatakan mirip.
- `Vektorisasi TF-IDF` : Tahap ini akan dilakukan proses vektorisasi dengan metode yang digunakan untuk menentukan nilai frekuensi sebuah kata di dalam sebuah dokumen atau artikel dan juga frekuensi di dalam banyak dokumen.
- `Cosine Similarity` : Tahap *Cosine Similarity* ditujukan untuk mengukur derajat kesamaan antara dua vektor dan menentukan apakah kedua vektor menunjuk ke arah yang sama. Cara kerja teknik ini dengan menghitung sudut cosinus antara dua vektor. Semakin kecil sudut cosinus antara dua vektor, semakin besar nilai kemiripan cosinusnya.
- `Get Top Recommendation` : Pada tahap ini dilakukan pengujian untuk mengetahui seberapa baik model dalam memberikan sebuah daftar rekomendasi dari sebuah fungsi yang akan menerima beberapa sebuah *input* dalam `nama_kosmetik, similarity_data, items, k` dengan definisi masing-masing parameter sebagai berikut:
    - nama_komsetik: Parameter masukkan nama kosmetik yang ingin diketahui rekomendasinya
    - similarity_data: Parameter yang berisi mengenai similarity yang telah dibuat
    - items: Parameter yang berisi Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah `Name` dan `Label`
    - k: Parameter untuk menentukan jumlah rekomendasi yang ingin diberikan
"""

data = dataset_init
data.sample(5)

"""###Vektorisasi TF-IDF"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()
tf.fit(data['Label'])
tf.get_feature_names_out()

print(len(tf.get_feature_names_out()))

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['Label'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

data['Label'].unique()

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan label
# Baris diisi dengan nama kosmetik

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data['Name']
).sample(9, axis=1).sample(10, axis=0)

"""### Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

pd.DataFrame(cosine_sim)

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['Name'], columns=data['Name'])
# cosine_sim_df = pd.DataFrame(cosine_sim, index=data['product_name'], columns=data['product_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Get Recommendation"""

def cosmetics_recommendations(nama_kosmetik, similarity_data=cosine_sim_df, items=data[['Name', 'Label']], k=5):
    """
    Rekomendasi Resto berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_kosmetik : tipe data string (str)
                Nama Kosmetik (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan label sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_kosmetik].to_numpy().argpartition(range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_kosmetik, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

test_value = "Help Me"

data[data['Name'].eq(test_value)]

# Mendapatkan rekomendasi kosmetik yang mirip dengan data `test_value`
cosmetics_recommendations(test_value, k=10)

data[data['Name'].eq('Acne Solutions BB Cream Broad Spectrum SPF 40')]

cosmetics_recommendations('Acne Solutions BB Cream Broad Spectrum SPF 40', k=10)

similarity_data = cosine_sim_df
# nama_resto = "Help Me"
# nama_resto = 'Acne-Clear Invisible Dots'
nama_resto = "Illuminating Eye Crème"
k = 5
items = data[['Name', 'Label']]
items

index = similarity_data.loc[:,nama_resto].to_numpy().argpartition(range(-1, -k, -1))
index

# Mengambil data dengan similarity terbesar dari index yang ada
closest = similarity_data.columns[index[-1:-(k+2):-1]]
closest

closest = pd.DataFrame(closest)
closest

# Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
closest = closest.drop(nama_resto, errors='ignore')
closest

output = pd.DataFrame(closest).merge(items).head(k)
output